# genomics-workshop

## Genomics workshop information

Data Carpentry workshops are for any researcher who has data they want to analyze , and no prior computational experience is required. This hands-on workshop teaches basic concepts, skills and tools for working more effectively with data.

The focus of this workshop will be on working with genomics data and data management and analysis for genomics research. We will cover metadata organization in spreadsheets, data organization, connecting to and using cloud computing, the command line for sequence quality control and bioinformatics workflows, and R for data analysis and visualization. We will not be teaching any particular bioinformatics tools, but the foundational skills that will allow you to conduct any analysis and analyze the output of a genomics pipeline.

Participants should bring their laptops and plan to participate actively. By the end of the workshop learners should be able to more effectively manage and analyze data and be able to apply the tools and approaches directly to their ongoing research.

Data Carpentry's aim is to teach researchers basic concepts, skills, and tools for working with data so that they can get more done in less time, and with less pain.

### Workshop structure

One dataset will be used throughout the workshop. We will start by introducing the dataset and the steps we'll go through 
for analysis. 

### Preliminary schedule

**Day 1 Morning**

Module 1: [Data organization and management](https://github.com/datacarpentry/organization-genomics)
- Setting up the project
- folder organization
- naming schemes
- keep raw data raw
- metadata

Module 2: [Working with genomics file types](https://github.com/datacarpentry/knowyourdata-genomics)  
- idea is that you can look at the data and understand how it's structured and how to use it

**Day 1 Afternoon**

Module 3: [Using cloud computing for genomics](https://github.com/datacarpentry/cloud-genomics)  
- log in to the cloud
- transfer some small data - maybe get it from a public repository
- maybe transfer data from local computer

Module 4: [Introduction to the command line](https://github.com/datacarpentry/shell-genomics)  
- command line 

**Day 2 Morning**

Module 5: [Data wrangling and processing](https://github.com/datacarpentry/wrangling-genomics)  
- running FastQC
- running Trimmomatic
- running FastQC to look at changes

**Day 2 Afternoon**

Module 5: [R for data analysis and visualization](https://github.com/datacarpentry/R-genomics)
- importing data in to R and using it for analysis and visualization
